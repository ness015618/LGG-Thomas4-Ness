{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` is a Python package providing fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way towards this goal.\n",
    "\n",
    "Prerequisite :\n",
    "- Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas (and Numpy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it is conventional to refer to `pandas` as `pd`.   \n",
    "When you add the `as pd` at the end of your import statement, your Jupyter Notebook understands that from this point on every time you type `pd`, you are actually referring to the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pandas_tutorial_read.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataframe in our variable df, let's look at what it contains. We can use the function `head()` to see the first couple rows of the dataframe (or the function `tail()` to see the last few rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ins</th>\n",
       "      <th>type_entity</th>\n",
       "      <th>entity</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>Région</td>\n",
       "      <td>Wallonie</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>Province</td>\n",
       "      <td>Brabant Wallon</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>367.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25000</td>\n",
       "      <td>Arrondissement</td>\n",
       "      <td>Nivelles</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>367.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25005</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Beauvechain</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>187.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25014</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Braine-l'Alleud</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>764.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ins     type_entity           entity      period  value\n",
       "0   3000          Région         Wallonie  01/01/2019  215.0\n",
       "1  20002        Province   Brabant Wallon  01/01/2019  367.9\n",
       "2  25000  Arrondissement         Nivelles  01/01/2019  367.9\n",
       "3  25005         Commune      Beauvechain  01/01/2019  187.8\n",
       "4  25014         Commune  Braine-l'Alleud  01/01/2019  764.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ins</th>\n",
       "      <th>type_entity</th>\n",
       "      <th>entity</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>93018</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Doische</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>93022</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Florennes</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>84.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>93056</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Philippeville</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>93088</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Walcourt</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>149.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>93090</td>\n",
       "      <td>Commune</td>\n",
       "      <td>Viroinval</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ins type_entity         entity      period  value\n",
       "286  93018     Commune        Doische  01/01/2019   35.6\n",
       "287  93022     Commune      Florennes  01/01/2019   84.3\n",
       "288  93056     Commune  Philippeville  01/01/2019   59.0\n",
       "289  93088     Commune       Walcourt  01/01/2019  149.1\n",
       "290  93090     Commune      Viroinval  01/01/2019   46.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the dimensions of the dataframe using the the `shape` attribute, like in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract all the column names as a list, by using the `columns` attribute and can extract the rows with the `index` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ins', 'type_entity', 'entity', 'period', 'value']\n",
      "Index(['ins', 'type_entity', 'entity', 'period', 'value'], dtype='object')\n",
      "RangeIndex(start=0, stop=291, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "print(df.columns)\n",
    "print(df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a better idea of the type of data that we are dealing with, we can call the `describe()` function to see statistics like mean, min, etc... about each column of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ins</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64080.941581</td>\n",
       "      <td>319.149828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19262.087619</td>\n",
       "      <td>428.431706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55019.500000</td>\n",
       "      <td>79.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62096.000000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>83020.500000</td>\n",
       "      <td>323.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93090.000000</td>\n",
       "      <td>3518.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ins        value\n",
       "count    291.000000   291.000000\n",
       "mean   64080.941581   319.149828\n",
       "std    19262.087619   428.431706\n",
       "min     3000.000000    24.500000\n",
       "25%    55019.500000    79.400000\n",
       "50%    62096.000000   186.000000\n",
       "75%    83020.500000   323.700000\n",
       "max    93090.000000  3518.600000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now let's look at information that we want to extract from the dataframe. Let's say I wanted to know the max value of a certain column. The function `max()` will show you the maximum value accross all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ins                 93090\n",
       "type_entity        Région\n",
       "entity             Étalle\n",
       "period         01/01/2019\n",
       "value              3518.6\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if you'd like to specifically get the max value for a particular column, you pass in the name of the column using the bracket indexing operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3518.6\n",
      "01/01/2019\n"
     ]
    }
   ],
   "source": [
    "print(df['value'].max())\n",
    "print(df['period'].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to find the mean of the column `'value'`, you can use the `mean()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319.1498281786941"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if that's not enough? Let's say we want to actually see the row where this max value is. We can call the `idxmax()` function to identify the row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].idxmax()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful functions that you can call on certain columns in a dataframe is the `value_counts()` function. It shows how many times each item appears in the column. This particular command shows the number of the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ins    type_entity     entity                   period      value\n",
       "57000  Arrondissement  Tournai-Mouscron         01/01/2019  312.6    2\n",
       "55000  Arrondissement  Soignies                 01/01/2019  292.3    2\n",
       "58000  Arrondissement  La Louvière              01/01/2019  642.8    2\n",
       "3000   Région          Wallonie                 01/01/2019  215.0    1\n",
       "64065  Commune         Saint-Georges-sur-Meuse  01/01/2019  325.3    1\n",
       "                                                                    ..\n",
       "58002  Commune         Binche                   01/01/2019  546.6    1\n",
       "58003  Commune         Estinnes                 01/01/2019  105.9    1\n",
       "58004  Commune         Morlanwelz               01/01/2019  935.7    1\n",
       "60000  Province        Liège                    01/01/2019  287.0    1\n",
       "93090  Commune         Viroinval                01/01/2019  46.7     1\n",
       "Name: count, Length: 288, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['value'].value_counts()\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('easy_pandas.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acessing Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in order to get a particular row of the dataframe, we need to use the `iloc[]` function. Iloc is definitely one of the more important functions. The main idea is that you want to use it whenever you have the integer index of a certain row that you want to access. As per the Pandas documentation, iloc is an \"integer-location based indexing for selection by position.\"\n",
    "(If you ask yourself: *Why the double brackets ?*; It is explained further.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[df['value'].idxmax()]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this a step further. Let's say you want to know the value of the column `'ins'` when the `'value'` column has its max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[df['value'].idxmax()]]['ins']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see data displayed in the above format, you're dealing with a Pandas `Series` object, not a dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[[df['value'].idxmax()]]['ins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[[df['value'].idxmax()]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other really important function in Pandas is the `loc` function. Contrary to `iloc`, which is an integer based indexing, `loc` is a \"Purely label-location based indexer for selection by label\". Since all the rows are ordrered by the `ins` column, `loc` and `iloc` are going to be pretty interchangeable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the slight difference in that **`iloc` is exclusive of the second number, while loc is inclusive**. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how you can use `loc` to achieve the same task as we did previously with `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['value'].idxmax(), 'ins']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faster version uses the `at()` function. `at()` is really useful whenever you know the row label and the column label of the particular value that you want to get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[df['value'].idxmax(), 'ins']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to see more discussion on how loc and iloc are different, check out this great Stack Overflow post: http://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanation. Just remember that **`iloc` looks at position** and **`loc` looks at labels**. `loc` becomes very important when your row labels aren't integers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to sort the dataframe in increasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('value').head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Rows Conditionally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say we want to find all of the rows that satisy a particular condition. For example, we want to find all the rows where `'value'` is higher than 150. The idea behind this command is you want to access the column `'value'` of the dataframe df (`df['value']`), find which entries are above 150 (`df['value'] > 150`), and then returns only those specific rows in a dataframe format (`df[df['value'] > 150]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['value'] > 150]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works if you have multiple conditions. Let's say we want to find out when the values between two specific values, here 150 and 200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['value'] > 150) & (df['value'] < 200)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important function in Pandas is `groupby` This is a function that allows you to group entries by certain attributes (e.g Grouping entries by `ins` number) and then perform operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('ins')['value'].mean().head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next command groups all the entities with the same value and finds how many times that specific entity appears on the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('value')['entity'].value_counts().head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataframe has a `values` attribute which is useful because it basically displays your dataframe in a numpy array style format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can simply just access elements like you would in an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to iterate through dataframes, we can use the `iterrows` function. Below is an example of what the first two rows look like. Each row in `df.iterrows()` is a `Series` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row)\n",
    "    if index == 1:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Rows and Columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bracket indexing operator is one way to extract certain columns from a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['entity', 'value']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you can achieve the same result by using the `loc` function. `loc` is a veryyyy versatile function that can help you in a lot of accessing and extracting tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['entity', 'value']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference is the return types when you use brackets and when you use double brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[['entity']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've seen before that you can access columns through `df['col name']`. You can also access rows by using slicing operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an equivalent using `iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:3,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the big jobs of doing well in [Kaggle competitions](https://www.kaggle.com/competitions) is the one of data cleaning. A lot of times, the CSV file you're given (especially like in the Titanic dataset), you'll have a lot of missing values in the dataset, which you have to identify. The following `isnull` function will figure out if there are any missing values in the dataframe, and will then sum up the total for each column. In this case, we have a pretty clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do end up having missing values in your datasets, be sure to get familiar with these two functions. \n",
    "* `dropna()` - This function allows you to drop all(or some) of the rows that have missing values. \n",
    "* `fillna()` - This function allows you replace the rows that have missing values with the value that you pass in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Kaggle Submission CSVs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't directly Pandas related, but most people who use Pandas probably do a lot of Kaggle competitions as well. As you probably know, Kaggle competitions require you to create a CSV of your predictions. Here's some starter code that can help you create that csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "results = [[0,10],[1,15],[2,20]]\n",
    "results = np.array(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstRow = [['id', 'pred']]\n",
    "with open(\"result.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(firstRow)\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach I described above deals more with python lists and numpy. If you want a purely Pandas based approach, take a look at this video: https://www.youtube.com/watch?v=ylRlGCtAtiE&list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y&index=22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Useful Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `drop()` - This function removes the column or row that you pass in (You also have the specify the axis). \n",
    "* `agg()` - The aggregate function lets you compute summary statistics about each group\n",
    "* `apply()` - Lets you apply a specific function to any/all elements in a Dataframe or Series\n",
    "* `get_dummies()` - Helpful for turning categorical data into one hot vectors.\n",
    "* `drop_duplicates()` - Lets you remove identical rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lots of Other Great Resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has been around for a while and there are a lot of other good resources if you're still interested on getting the most out of this library. \n",
    "* http://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "* https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n",
    "* http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/\n",
    "* https://www.dataquest.io/blog/pandas-python-tutorial/\n",
    "* https://www.youtube.com/playlist?list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
